[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "I. Collect data (Tweets) from Twitter using R\nA. Clean the data with R\nB. Store all the data in a postgreSQL database\nII. After a period of data collection, use R to connect to the database\nA. Use SQL to query the database via R\nB. Store SQL query outputs as data frames for R analysis\nIII. Investigate insights in the data\nA. Sentiment analysis\nB. Word correlations\nC. Create visualizations as the deliverable and a “discussion”\n\n\n\n\nGitHub Profile Link\nProject Repository Link\n\n\n\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "pogo.html",
    "href": "pogo.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "library(tidyverse)\nlibrary(rtweet)\n\nauth_setup_default()\nauth_has_default()\n\n[1] TRUE\n\n\n\npdf <- search_tweets(\"pokemon go\", n = 1000, include_rts = FALSE, lang = \"en\")\n\n\n# data\npdf1 <- pdf %>%\n  select(id_str, retweet_count, favorite_count,  created_at)\n\n#text\npdf2 <- pdf %>%\n  select(id_str, full_text, display_text_range, text)\n\n\nlibrary(DBI)\nlibrary(RPostgres)\nlibrary(dplyr)\n\ncon <- dbConnect(RPostgres::Postgres(),dbname = 'postgres',\n      host = 'localhost',\n      port = 5432,\n      user = 'postgres',\n      password = 'vannah')\n\n\ndbWriteTable(con, \"pogo_data\", pdf1, append = TRUE)\ndbWriteTable(con, \"pogo_text\", pdf2, append = TRUE)\n\n\n# disconnect from database\ndbDisconnect(con)"
  },
  {
    "objectID": "rocket_league.html",
    "href": "rocket_league.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "# load packages\nlibrary(DBI) # to connect to database\nlibrary(RPostgres) # to connect to database\nlibrary(dplyr) # to wrangle data\nlibrary(tidytext) # wrangle text data\nlibrary(tidyverse) # meta tidyverse package\nlibrary(RColorBrewer) # for color brewing\nlibrary(widyr) # for pairwise correlation \nlibrary(igraph) # for data visualization\nlibrary(ggraph) # for data visualization\n\n# connect to database\ncon <- dbConnect(RPostgres::Postgres(),dbname = 'postgres',\n                 host = 'localhost',\n                 port = 5432,\n                 user = 'postgres',\n                 password = 'vannah') \n\n# make and execute query\nres <- dbSendQuery(con, \"\n\nSELECT DISTINCT(t.id_str), text, display_text_range, retweet_count, favorite_count\nFROM rocketleague_text AS t\nINNER JOIN rocketleague_data AS d\nON d.id_str = t.id_str\n\n-- DISTINCT(t.id_str) eliminates duplicates \n                   \n                   \")\n\nquery_df <- dbFetch(res)\n\n# clear query and disconnect from database\ndbClearResult(res)\ndbDisconnect(con)\n\n# clean data\ndb_new <- unnest_tokens(tbl = query_df, input = text, output = word)\n\nstp_wrds <- get_stopwords(source = \"smart\")\n\ndb_new <- anti_join(db_new, stp_wrds, by = \"word\")\n\nbing <- get_sentiments(lexicon = \"bing\")\n\ndb_bing <- inner_join(db_new, bing, by = \"word\")\n\ndb_bing <- count(db_bing, id_str, display_text_range, retweet_count, favorite_count, word, sentiment)\n\ndb_bing <- spread(key = sentiment, value = n, fill = 0, data = db_bing)\n\n\ndb_bing <- mutate(sentiment = positive - negative, .data = db_bing)\n\nmean(db_bing$sentiment, na.rm = TRUE)\n\n[1] 0.06984553\n\n\n\n\n\nfun_color_range <- colorRampPalette(c(\"red\", \"green\"))\nmy_colors2 <- fun_color_range(2)\n\ndb_sentiment <- db_bing %>% \n  mutate(value = case_when(sentiment > 0 ~ 'positive',\n                           sentiment == 0 ~ 'neutral',\n                           sentiment < 0 ~ 'negative')) %>%\n  filter(value == 'positive' | value == 'negative')\n\nrl_sentiment <- db_sentiment %>%\n  group_by(id_str) %>%\n  summarise( display_text_range = mean(display_text_range), Sentiment = sum(sentiment)) %>% \n  filter(display_text_range < 280) %>%\n  ggplot(mapping = aes(x = display_text_range, y = Sentiment, color = Sentiment)) +\n  geom_jitter(alpha = .5) + \n  scale_colour_gradientn(colors = my_colors2) +\n  geom_hline(linetype = 1, yintercept = 0, size = .5) +\n  geom_vline(linetype = 1, xintercept = 140, size = .5) +\n  theme_classic() +\n  theme() + \n  labs(title = \"Rocket League Tweet Sentiment\", x = \"Number of Characters\", y = \"Sentiment\")\nrl_sentiment\n\n\n\n\n\n\n\n\ntweet_words <- query_df %>% \n  unnest_tokens(output = word, input = text) %>% \n  anti_join(stop_words, by = \"word\") %>% \n  filter(str_detect(word, \"[:alpha:]\")) %>% \n  distinct()\n\n#---- remove non-words ----#\nword <- c('https','t.co', 'ttv', 'bcluhhk8eu')\nextra2 <- data.frame(word)\n\ntweet_words <- tweet_words %>%\n  anti_join(extra2, by = \"word\")\n\n#---- first visual ----#\ntweets_that_mention_word <- tweet_words %>% \n  count(word, name = \"number_of_tweets\") %>% \n  filter(number_of_tweets >= 7)\n\n\ntweet_correlations <- tweet_words %>% \n  semi_join(tweets_that_mention_word, by = \"word\") %>% \n  pairwise_cor(item = word, feature = id_str) %>% \n  filter(correlation >= 0.7) \n\n\nrl_correlations <- graph_from_data_frame(d = tweet_correlations,\n                      vertices = tweets_that_mention_word %>%\n                        semi_join(tweet_correlations, by = c(\"word\" = \"item1\"))) %>%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = correlation)) + \n  geom_node_point() +\n  geom_node_text(aes(color = number_of_tweets, label = name), repel = TRUE, check_overlap = TRUE, size = 4) + \n  labs(title = \"Rocket League Tweets\") +\n  scale_colour_gradientn(colours=c(\"#3e3b92\", \"#f44369\")) +\n  theme(panel.background = element_rect(fill = \"#eaeaea\"),\n        plot.background = element_rect(fill = \"#ffffff\"))\nrl_correlations"
  },
  {
    "objectID": "rstats.html",
    "href": "rstats.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "library(tidyverse)\nlibrary(rtweet)\n\nauth_setup_default()\nauth_has_default()\n\n[1] TRUE\n\n\n\nrdf <- search_tweets(\"#rstats\", n = 1000, include_rts = FALSE, lang = \"en\")\n\n\n# data\nrdf1 <- rdf %>%\n  select(id_str, retweet_count, favorite_count,  created_at)\n\n# text\nrdf2 <- rdf %>%\n  select(id_str, full_text, display_text_range, text)\n\n\nlibrary(DBI)\nlibrary(RPostgres)\nlibrary(dplyr)\n\ncon <- dbConnect(RPostgres::Postgres(),dbname = 'postgres',\n      host = 'localhost',\n      port = 5432,\n      user = 'postgres',\n      password = 'vannah') \n\n\ndbWriteTable(con, \"rstats_data\", rdf1, append = TRUE)\ndbWriteTable(con, \"rstats_text\", rdf2, append = TRUE)\n\n\n# disconnect from database\ndbDisconnect(con)"
  },
  {
    "objectID": "topgolf.html",
    "href": "topgolf.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "library(tidyverse)\nlibrary(rtweet)\n\nauth_setup_default()\nauth_has_default()\n\n[1] TRUE\n\n\n\ntgdf <- search_tweets(\"topgolf\", n = 1000, include_rts = FALSE, lang = \"en\")\n\n\n# data\ntgdf1 <- tgdf %>%\n  select(id_str, retweet_count, favorite_count,  created_at)\n\n#text\ntgdf2 <- tgdf %>%\n  select(id_str, full_text, display_text_range, text)\n\n\nlibrary(DBI)\nlibrary(RPostgres)\nlibrary(dplyr)\n\ncon <- dbConnect(RPostgres::Postgres(),dbname = 'postgres',\n      host = 'localhost',\n      port = 5432,\n      user = 'postgres',\n      password = 'vannah')\n\n\ndbWriteTable(con, \"tg_data\", tgdf1, append = TRUE)\ndbWriteTable(con, \"tg_text\", tgdf2, append = TRUE)\n\n\n# disconnect from database\ndbDisconnect(con)"
  },
  {
    "objectID": "tweet_scrape.html",
    "href": "tweet_scrape.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "In order to get the Tweets I will first need to load the packages tidyverse and rtweet.\n\nlibrary(tidyverse)\nlibrary(rtweet)\n\nNext I can authenticate my Twitter developer account.\n\nauth_setup_default()\nauth_has_default()\n\n[1] TRUE\n\n\n\n\nFinally I will then search and scrape tweets that contain ‘rocket league’, I am doing 1000 Tweets at a time, that do not include Retweets and are in English.\n\ndf <- search_tweets(\"rocket league\", n = 1000, include_rts = FALSE, lang = \"en\")\n\n\n\nNow I will clean up the dataset into two more manageable tables that will be imported into my postgreSQL database.\n\ndf1 <- df %>%\n  select(id_str, retweet_count, favorite_count,  created_at)\n\ndf2 <- df %>%\n  select(id_str, full_text, display_text_range, text)\n\n\n\n\n\n# packages for database connection\nlibrary(DBI)\nlibrary(RPostgres)\nlibrary(dplyr)\n\n# establish connection with postgres database\ncon <- dbConnect(RPostgres::Postgres(),dbname = 'postgres',\n      host = 'localhost',\n      port = 5432,\n      user = 'postgres',\n      password = 'vannah') \n\n\n\n\n\ndbWriteTable(con, \"rldata\", df1, append = TRUE)\ndbWriteTable(con, \"rltext\", df2, append = TRUE)\n\n\n\n\n\n\npdf <- search_tweets(\"pokemon go\", n = 1000, include_rts = FALSE, lang = \"en\")\n\n\n\n\npdf1 <- pdf %>%\n  select(id_str, retweet_count, favorite_count,  created_at)\n\npdf2 <- pdf %>%\n  select(id_str, full_text, display_text_range, text)\n\n\n\n\n\ndbWriteTable(con, \"pogodata\", pdf1, append = TRUE)\ndbWriteTable(con, \"pogotext\", pdf2, append = TRUE)\n\n\n\n\n\n# disconnect from database\ndbDisconnect(con)"
  },
  {
    "objectID": "rl-analysis-temp.html",
    "href": "rl-analysis-temp.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "#----  ----#\nlibrary(RColorBrewer)\nfun_color_range <- colorRampPalette(c(\"red\", \"green\"))\nmy_colors2 <- fun_color_range(2)\n\ndb_sentiment <- db_bing %>% \n  mutate(value = case_when(sentiment > 0 ~ 'positive',\n                           sentiment == 0 ~ 'neutral',\n                           sentiment < 0 ~ 'negative')) %>%\n  filter(value == 'positive' | value == 'negative')\n\nrl_sentiment <- db_sentiment %>%\n  group_by(id_str) %>%\n  summarise( display_text_range = mean(display_text_range), Sentiment = sum(sentiment)) %>% \n  filter(display_text_range < 280) %>%\n  ggplot(mapping = aes(x = display_text_range, y = Sentiment, color = Sentiment)) +\n  geom_jitter(alpha = .5) + \n  scale_colour_gradientn(colors = my_colors2) +\n  geom_hline(linetype = 1, yintercept = 0, size = .5) +\n  geom_vline(linetype = 1, xintercept = 140, size = .5) +\n  theme_classic() +\n  theme() + \n  labs(title = \"Rocket League Tweet Sentiment\", x = \"Number of Characters\", y = \"Sentiment\")\n\n\nlibrary(tidytext)\nlibrary(tidyverse)\nlibrary(widyr) # for pairwise correlation \nlibrary(igraph) # for data visualization\n\nWarning: package 'igraph' was built under R version 4.1.3\n\n\n\nAttaching package: 'igraph'\n\n\nThe following objects are masked from 'package:purrr':\n\n    compose, simplify\n\n\nThe following object is masked from 'package:tidyr':\n\n    crossing\n\n\nThe following object is masked from 'package:tibble':\n\n    as_data_frame\n\n\nThe following objects are masked from 'package:dplyr':\n\n    as_data_frame, groups, union\n\n\nThe following objects are masked from 'package:stats':\n\n    decompose, spectrum\n\n\nThe following object is masked from 'package:base':\n\n    union\n\nlibrary(ggraph) # for data visualization\n\nWarning: package 'ggraph' was built under R version 4.1.3\n\ntweet_words <- query_df %>% \n  unnest_tokens(output = word, input = text) %>% \n  anti_join(stop_words, by = \"word\") %>% \n  filter(str_detect(word, \"[:alpha:]\")) %>% \n  distinct()\n\n#---- remove non-words ----#\nword <- c('https','t.co', 'ttv', 'bcluhhk8eu')\nextra2 <- data.frame(word)\n\ntweet_words <- tweet_words %>%\n  anti_join(extra2, by = \"word\")\n\n#---- first visual ----#\ntweets_that_mention_word <- tweet_words %>% \n  count(word, name = \"number_of_tweets\") %>% \n  filter(number_of_tweets >= 7)\n\n\ntweet_correlations <- tweet_words %>% \n  semi_join(tweets_that_mention_word, by = \"word\") %>% \n  pairwise_cor(item = word, feature = id_str) %>% \n  filter(correlation >= 0.7) \n\n\nrl_correlations <- graph_from_data_frame(d = tweet_correlations,\n                      vertices = tweets_that_mention_word %>%\n                        semi_join(tweet_correlations, by = c(\"word\" = \"item1\"))) %>%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = correlation)) + \n  geom_node_point() +\n  geom_node_text(aes(color = number_of_tweets, label = name), repel = TRUE, check_overlap = TRUE, size = 4) + \n  labs(title = \"Rocket League Tweets\") +\n  scale_colour_gradientn(colours=c(\"#3e3b92\", \"#f44369\")) +\n  theme(panel.background = element_rect(fill = \"#eaeaea\"),\n        plot.background = element_rect(fill = \"#ffffff\"))"
  }
]