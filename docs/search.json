[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "I. Collect data (Tweets) from Twitter using R\nA. Clean the data with R\nB. Store all the data in a postgreSQL database\nII. After a period of data collection, use R to connect to the database\nA. Use SQL to query the database via R\nB. Store SQL query outputs as data frames for R analysis\nIII. Investigate insights in the data\nA. Sentiment analysis\nB. Word correlations\nC. Create visualizations as the deliverable and a “discussion”\n\n\n\n\n \n\n\n\nGitHub Profile Link\nProject Repository Link\n\n\n\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "pogo.html",
    "href": "pogo.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "pg_sentiment\n\n\n\n\n\n\n\n\npg_correlations"
  },
  {
    "objectID": "rl-analysis-temp.html",
    "href": "rl-analysis-temp.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "#----  ----#\nlibrary(RColorBrewer)\nfun_color_range <- colorRampPalette(c(\"red\", \"green\"))\nmy_colors2 <- fun_color_range(2)\n\ndb_sentiment <- db_bing %>% \n  mutate(value = case_when(sentiment > 0 ~ 'positive',\n                           sentiment == 0 ~ 'neutral',\n                           sentiment < 0 ~ 'negative')) %>%\n  filter(value == 'positive' | value == 'negative')\n\nrl_sentiment <- db_sentiment %>%\n  group_by(id_str) %>%\n  summarise( display_text_range = mean(display_text_range), Sentiment = sum(sentiment)) %>% \n  filter(display_text_range < 280) %>%\n  ggplot(mapping = aes(x = display_text_range, y = Sentiment, color = Sentiment)) +\n  geom_jitter(alpha = .5) + \n  scale_colour_gradientn(colors = my_colors2) +\n  geom_hline(linetype = 1, yintercept = 0, size = .5) +\n  geom_vline(linetype = 1, xintercept = 140, size = .5) +\n  theme_classic() +\n  theme() + \n  labs(title = \"Rocket League Tweet Sentiment\", x = \"Number of Characters\", y = \"Sentiment\")\n\n\nlibrary(tidytext)\nlibrary(tidyverse)\nlibrary(widyr) # for pairwise correlation \nlibrary(igraph) # for data visualization\n\nWarning: package 'igraph' was built under R version 4.1.3\n\n\n\nAttaching package: 'igraph'\n\n\nThe following objects are masked from 'package:purrr':\n\n    compose, simplify\n\n\nThe following object is masked from 'package:tidyr':\n\n    crossing\n\n\nThe following object is masked from 'package:tibble':\n\n    as_data_frame\n\n\nThe following objects are masked from 'package:dplyr':\n\n    as_data_frame, groups, union\n\n\nThe following objects are masked from 'package:stats':\n\n    decompose, spectrum\n\n\nThe following object is masked from 'package:base':\n\n    union\n\nlibrary(ggraph) # for data visualization\n\nWarning: package 'ggraph' was built under R version 4.1.3\n\ntweet_words <- query_df %>% \n  unnest_tokens(output = word, input = text) %>% \n  anti_join(stop_words, by = \"word\") %>% \n  filter(str_detect(word, \"[:alpha:]\")) %>% \n  distinct()\n\n#---- remove non-words ----#\nword <- c('https','t.co', 'ttv', 'bcluhhk8eu')\nextra2 <- data.frame(word)\n\ntweet_words <- tweet_words %>%\n  anti_join(extra2, by = \"word\")\n\n#---- first visual ----#\ntweets_that_mention_word <- tweet_words %>% \n  count(word, name = \"number_of_tweets\") %>% \n  filter(number_of_tweets >= 7)\n\n\ntweet_correlations <- tweet_words %>% \n  semi_join(tweets_that_mention_word, by = \"word\") %>% \n  pairwise_cor(item = word, feature = id_str) %>% \n  filter(correlation >= 0.7) \n\n\nrl_correlations <- graph_from_data_frame(d = tweet_correlations,\n                      vertices = tweets_that_mention_word %>%\n                        semi_join(tweet_correlations, by = c(\"word\" = \"item1\"))) %>%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = correlation)) + \n  geom_node_point() +\n  geom_node_text(aes(color = number_of_tweets, label = name), repel = TRUE, check_overlap = TRUE, size = 4) + \n  labs(title = \"Rocket League Tweets\") +\n  scale_colour_gradientn(colours=c(\"#3e3b92\", \"#f44369\")) +\n  theme(panel.background = element_rect(fill = \"#eaeaea\"),\n        plot.background = element_rect(fill = \"#ffffff\"))"
  },
  {
    "objectID": "rocket_league.html",
    "href": "rocket_league.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "rl_sentiment\n\n\n\n\n\n\n\n\nrl_correlations"
  },
  {
    "objectID": "scrape.html",
    "href": "scrape.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)\nlibrary(rtweet)\nlibrary(DBI)\nlibrary(RPostgres)\nlibrary(dplyr)\n\nauth_setup_default()\nauth_has_default()\n\ndf <- search_tweets(\"rocket league\", n = 1000, include_rts = FALSE, lang = \"en\")\n\n# data\ndf1 <- df %>%\n  select(id_str, retweet_count, favorite_count,  created_at)\n\n# text\ndf2 <- df %>%\n  select(id_str, full_text, display_text_range, text)\n\n# connect to database\ncon <- dbConnect(RPostgres::Postgres(),dbname = 'postgres',\n      host = 'localhost',\n      port = 5432,\n      user = 'postgres',\n      password = 'vannah')\n\n# create tables in database\ndbWriteTable(con, \"rocketleague_data\", df1, append = TRUE)\ndbWriteTable(con, \"rocketleague_text\", df2, append = TRUE)\n\n# disconnect from database\ndbDisconnect(con)"
  },
  {
    "objectID": "scrape.html#rstats-tweets",
    "href": "scrape.html#rstats-tweets",
    "title": "Twitter Analysis Project",
    "section": "#rstats tweets",
    "text": "#rstats tweets\n\n# load packages\nlibrary(tidyverse)\nlibrary(rtweet)\nlibrary(DBI)\nlibrary(RPostgres)\nlibrary(dplyr)\n\nauth_setup_default()\nauth_has_default()\n\nrdf <- search_tweets(\"#rstats\", n = 1000, include_rts = FALSE, lang = \"en\")\n\n# data\nrdf1 <- rdf %>%\n  select(id_str, retweet_count, favorite_count,  created_at)\n\n# text\nrdf2 <- rdf %>%\n  select(id_str, full_text, display_text_range, text)\n\n# connect to database\ncon <- dbConnect(RPostgres::Postgres(),dbname = 'postgres',\n      host = 'localhost',\n      port = 5432,\n      user = 'postgres',\n      password = 'vannah')\n\n# create tables in database\ndbWriteTable(con, \"rstats_data\", rdf1, append = TRUE)\ndbWriteTable(con, \"rstats_text\", rdf2, append = TRUE)\n\n# disconnect from database\ndbDisconnect(con)"
  },
  {
    "objectID": "scrape.html#topgolf-tweets",
    "href": "scrape.html#topgolf-tweets",
    "title": "Twitter Analysis Project",
    "section": "TopGolf Tweets",
    "text": "TopGolf Tweets\n\n# load packages\nlibrary(tidyverse)\nlibrary(rtweet)\nlibrary(DBI)\nlibrary(RPostgres)\nlibrary(dplyr)\n\nauth_setup_default()\nauth_has_default()\n\ntgdf <- search_tweets(\"topgolf\", n = 1000, include_rts = FALSE, lang = \"en\")\n\n# data\ntgdf1 <- tgdf %>%\n  select(id_str, retweet_count, favorite_count,  created_at)\n\n# text\ntgdf2 <- tgdf %>%\n  select(id_str, full_text, display_text_range, text)\n\n# connect to database\ncon <- dbConnect(RPostgres::Postgres(),dbname = 'postgres',\n      host = 'localhost',\n      port = 5432,\n      user = 'postgres',\n      password = 'vannah')\n\n# create tables in database\ndbWriteTable(con, \"tg_data\", tgdf1, append = TRUE)\ndbWriteTable(con, \"tg_text\", tgdf2, append = TRUE)\n\n# disconnect from database\ndbDisconnect(con)"
  },
  {
    "objectID": "tweet_scrape.html",
    "href": "tweet_scrape.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "In order to get the Tweets I will first need to load the packages tidyverse and rtweet.\n\nlibrary(tidyverse)\nlibrary(rtweet)\n\nNext I can authenticate my Twitter developer account.\n\nauth_setup_default()\nauth_has_default()\n\n[1] TRUE\n\n\n\n\nFinally I will then search and scrape tweets that contain ‘rocket league’, I am doing 1000 Tweets at a time, that do not include Retweets and are in English.\n\ndf <- search_tweets(\"rocket league\", n = 1000, include_rts = FALSE, lang = \"en\")\n\n\n\nNow I will clean up the dataset into two more manageable tables that will be imported into my postgreSQL database.\n\ndf1 <- df %>%\n  select(id_str, retweet_count, favorite_count,  created_at)\n\ndf2 <- df %>%\n  select(id_str, full_text, display_text_range, text)\n\n\n\n\n\n# packages for database connection\nlibrary(DBI)\nlibrary(RPostgres)\nlibrary(dplyr)\n\n# establish connection with postgres database\ncon <- dbConnect(RPostgres::Postgres(),dbname = 'postgres',\n      host = 'localhost',\n      port = 5432,\n      user = 'postgres',\n      password = 'vannah') \n\n\n\n\n\ndbWriteTable(con, \"rldata\", df1, append = TRUE)\ndbWriteTable(con, \"rltext\", df2, append = TRUE)\n\n\n\n\n\n\npdf <- search_tweets(\"pokemon go\", n = 1000, include_rts = FALSE, lang = \"en\")\n\n\n\n\npdf1 <- pdf %>%\n  select(id_str, retweet_count, favorite_count,  created_at)\n\npdf2 <- pdf %>%\n  select(id_str, full_text, display_text_range, text)\n\n\n\n\n\ndbWriteTable(con, \"pogodata\", pdf1, append = TRUE)\ndbWriteTable(con, \"pogotext\", pdf2, append = TRUE)\n\n\n\n\n\n# disconnect from database\ndbDisconnect(con)"
  },
  {
    "objectID": "topgolf.html",
    "href": "topgolf.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "tg_sentiment\n\n\n\n\n\n\n\n\ntg_correlations"
  },
  {
    "objectID": "rstats.html",
    "href": "rstats.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "r_sentiment\n\n\n\n\n\n\n\n\nr_correlations"
  }
]