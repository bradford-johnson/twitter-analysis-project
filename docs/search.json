[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "I. Collect data (Tweets) from Twitter using R\nA. Clean the data with R\nB. Store all the data in a postgreSQL database\nII. After a period of data collection, use R to connect to the database\nA. Use SQL to query the database via R\nB. Store SQL query outputs as data frames for R analysis\nIII. Investigate insights in the data\nA. Sentiment analysis\nB. Word correlations\nC. Create visualizations as the deliverable and a “discussion”\n\n\n\n\n \n\n\n\nGitHub Profile Link\nProject Repository Link\n\n\n\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "pogo.html",
    "href": "pogo.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "pg_sentiment\n\n\n\n\n\n\n\n\npg_correlations"
  },
  {
    "objectID": "rl-analysis-temp.html",
    "href": "rl-analysis-temp.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "#----  ----#\nlibrary(RColorBrewer)\nfun_color_range <- colorRampPalette(c(\"red\", \"green\"))\nmy_colors2 <- fun_color_range(2)\n\ndb_sentiment <- db_bing %>% \n  mutate(value = case_when(sentiment > 0 ~ 'positive',\n                           sentiment == 0 ~ 'neutral',\n                           sentiment < 0 ~ 'negative')) %>%\n  filter(value == 'positive' | value == 'negative')\n\nrl_sentiment <- db_sentiment %>%\n  group_by(id_str) %>%\n  summarise( display_text_range = mean(display_text_range), Sentiment = sum(sentiment)) %>% \n  filter(display_text_range < 280) %>%\n  ggplot(mapping = aes(x = display_text_range, y = Sentiment, color = Sentiment)) +\n  geom_jitter(alpha = .5) + \n  scale_colour_gradientn(colors = my_colors2) +\n  geom_hline(linetype = 1, yintercept = 0, size = .5) +\n  geom_vline(linetype = 1, xintercept = 140, size = .5) +\n  theme_classic() +\n  theme() + \n  labs(title = \"Rocket League Tweet Sentiment\", x = \"Number of Characters\", y = \"Sentiment\")\n\n\nlibrary(tidytext)\nlibrary(tidyverse)\nlibrary(widyr) # for pairwise correlation \nlibrary(igraph) # for data visualization\n\nWarning: package 'igraph' was built under R version 4.1.3\n\n\n\nAttaching package: 'igraph'\n\n\nThe following objects are masked from 'package:purrr':\n\n    compose, simplify\n\n\nThe following object is masked from 'package:tidyr':\n\n    crossing\n\n\nThe following object is masked from 'package:tibble':\n\n    as_data_frame\n\n\nThe following objects are masked from 'package:dplyr':\n\n    as_data_frame, groups, union\n\n\nThe following objects are masked from 'package:stats':\n\n    decompose, spectrum\n\n\nThe following object is masked from 'package:base':\n\n    union\n\nlibrary(ggraph) # for data visualization\n\nWarning: package 'ggraph' was built under R version 4.1.3\n\ntweet_words <- query_df %>% \n  unnest_tokens(output = word, input = text) %>% \n  anti_join(stop_words, by = \"word\") %>% \n  filter(str_detect(word, \"[:alpha:]\")) %>% \n  distinct()\n\n#---- remove non-words ----#\nword <- c('https','t.co', 'ttv', 'bcluhhk8eu')\nextra2 <- data.frame(word)\n\ntweet_words <- tweet_words %>%\n  anti_join(extra2, by = \"word\")\n\n#---- first visual ----#\ntweets_that_mention_word <- tweet_words %>% \n  count(word, name = \"number_of_tweets\") %>% \n  filter(number_of_tweets >= 7)\n\n\ntweet_correlations <- tweet_words %>% \n  semi_join(tweets_that_mention_word, by = \"word\") %>% \n  pairwise_cor(item = word, feature = id_str) %>% \n  filter(correlation >= 0.7) \n\n\nrl_correlations <- graph_from_data_frame(d = tweet_correlations,\n                      vertices = tweets_that_mention_word %>%\n                        semi_join(tweet_correlations, by = c(\"word\" = \"item1\"))) %>%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = correlation)) + \n  geom_node_point() +\n  geom_node_text(aes(color = number_of_tweets, label = name), repel = TRUE, check_overlap = TRUE, size = 4) + \n  labs(title = \"Rocket League Tweets\") +\n  scale_colour_gradientn(colours=c(\"#3e3b92\", \"#f44369\")) +\n  theme(panel.background = element_rect(fill = \"#eaeaea\"),\n        plot.background = element_rect(fill = \"#ffffff\"))"
  },
  {
    "objectID": "rocket_league.html",
    "href": "rocket_league.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "rl_sentiment\n\n\n\n\n\n\n\n\nrl_correlations"
  },
  {
    "objectID": "scrape.html",
    "href": "scrape.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)\nlibrary(rtweet)\nlibrary(DBI)\nlibrary(RPostgres)\nlibrary(dplyr)\n\nauth_setup_default()\nauth_has_default()\n\ndf <- search_tweets(\"rocket league\", n = 1000, include_rts = FALSE, lang = \"en\")\n\n# data\ndf1 <- df %>%\n  select(id_str, retweet_count, favorite_count,  created_at)\n\n# text\ndf2 <- df %>%\n  select(id_str, full_text, display_text_range, text)\n\n# connect to database\ncon <- dbConnect(RPostgres::Postgres(),dbname = 'postgres',\n      host = 'localhost',\n      port = 5432,\n      user = 'postgres',\n      password = 'vannah')\n\n# create tables in database\ndbWriteTable(con, \"rocketleague_data\", df1, append = TRUE)\ndbWriteTable(con, \"rocketleague_text\", df2, append = TRUE)\n\n# disconnect from database\ndbDisconnect(con)"
  },
  {
    "objectID": "scrape.html#rstats-tweets",
    "href": "scrape.html#rstats-tweets",
    "title": "Twitter Analysis Project",
    "section": "#rstats tweets",
    "text": "#rstats tweets\n\n# load packages\nlibrary(tidyverse)\nlibrary(rtweet)\nlibrary(DBI)\nlibrary(RPostgres)\nlibrary(dplyr)\n\nauth_setup_default()\nauth_has_default()\n\nrdf <- search_tweets(\"#rstats\", n = 1000, include_rts = FALSE, lang = \"en\")\n\n# data\nrdf1 <- rdf %>%\n  select(id_str, retweet_count, favorite_count,  created_at)\n\n# text\nrdf2 <- rdf %>%\n  select(id_str, full_text, display_text_range, text)\n\n# connect to database\ncon <- dbConnect(RPostgres::Postgres(),dbname = 'postgres',\n      host = 'localhost',\n      port = 5432,\n      user = 'postgres',\n      password = 'vannah')\n\n# create tables in database\ndbWriteTable(con, \"rstats_data\", rdf1, append = TRUE)\ndbWriteTable(con, \"rstats_text\", rdf2, append = TRUE)\n\n# disconnect from database\ndbDisconnect(con)"
  },
  {
    "objectID": "scrape.html#topgolf-tweets",
    "href": "scrape.html#topgolf-tweets",
    "title": "Twitter Analysis Project",
    "section": "TopGolf Tweets",
    "text": "TopGolf Tweets\n\n# load packages\nlibrary(tidyverse)\nlibrary(rtweet)\nlibrary(DBI)\nlibrary(RPostgres)\nlibrary(dplyr)\n\nauth_setup_default()\nauth_has_default()\n\ntgdf <- search_tweets(\"topgolf\", n = 1000, include_rts = FALSE, lang = \"en\")\n\n# data\ntgdf1 <- tgdf %>%\n  select(id_str, retweet_count, favorite_count,  created_at)\n\n# text\ntgdf2 <- tgdf %>%\n  select(id_str, full_text, display_text_range, text)\n\n# connect to database\ncon <- dbConnect(RPostgres::Postgres(),dbname = 'postgres',\n      host = 'localhost',\n      port = 5432,\n      user = 'postgres',\n      password = 'vannah')\n\n# create tables in database\ndbWriteTable(con, \"tg_data\", tgdf1, append = TRUE)\ndbWriteTable(con, \"tg_text\", tgdf2, append = TRUE)\n\n# disconnect from database\ndbDisconnect(con)"
  },
  {
    "objectID": "tweet_scrape.html",
    "href": "tweet_scrape.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "In order to get the Tweets I will first need to load the packages tidyverse and rtweet.\n\nlibrary(tidyverse)\nlibrary(rtweet)\n\nNext I can authenticate my Twitter developer account.\n\nauth_setup_default()\nauth_has_default()\n\n[1] TRUE\n\n\n\n\nFinally I will then search and scrape tweets that contain ‘rocket league’, I am doing 1000 Tweets at a time, that do not include Retweets and are in English.\n\ndf <- search_tweets(\"rocket league\", n = 1000, include_rts = FALSE, lang = \"en\")\n\n\n\nNow I will clean up the dataset into two more manageable tables that will be imported into my postgreSQL database.\n\ndf1 <- df %>%\n  select(id_str, retweet_count, favorite_count,  created_at)\n\ndf2 <- df %>%\n  select(id_str, full_text, display_text_range, text)\n\n\n\n\n\n# packages for database connection\nlibrary(DBI)\nlibrary(RPostgres)\nlibrary(dplyr)\n\n# establish connection with postgres database\ncon <- dbConnect(RPostgres::Postgres(),dbname = 'postgres',\n      host = 'localhost',\n      port = 5432,\n      user = 'postgres',\n      password = 'vannah') \n\n\n\n\n\ndbWriteTable(con, \"rldata\", df1, append = TRUE)\ndbWriteTable(con, \"rltext\", df2, append = TRUE)\n\n\n\n\n\n\npdf <- search_tweets(\"pokemon go\", n = 1000, include_rts = FALSE, lang = \"en\")\n\n\n\n\npdf1 <- pdf %>%\n  select(id_str, retweet_count, favorite_count,  created_at)\n\npdf2 <- pdf %>%\n  select(id_str, full_text, display_text_range, text)\n\n\n\n\n\ndbWriteTable(con, \"pogodata\", pdf1, append = TRUE)\ndbWriteTable(con, \"pogotext\", pdf2, append = TRUE)\n\n\n\n\n\n# disconnect from database\ndbDisconnect(con)"
  },
  {
    "objectID": "topgolf.html",
    "href": "topgolf.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "tg_sentiment\n\n\n\n\n\n\n\n\ntg_correlations"
  },
  {
    "objectID": "rstats.html",
    "href": "rstats.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "r_sentiment\n\n\n\n\n\n\n\n\nr_correlations"
  },
  {
    "objectID": "patchwork.html",
    "href": "patchwork.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "Using sentiment analysis is an effective way to see how end users feel about a product or service. Social media is used to communicate with audiences, and it is a great place to obtain insights. Businesses will always be focused on their online presence, as it can be used in many ways to ensure quality customer experiences with their products or services.\n\n\n\n\nA Tweet’s sentiment is measured by assigning numerical values to words based on their inherent sentiment. An example of a word with positive sentiment would be \"love\" and a word with negative sentiment would be \"hate\". For all the words within a Tweet the sentiment is aggregated and this is how the overall “Tweet Sentiment” is obtained.\n\n\n\nOften in sentiment analysis stop words are removed from the data as they take up resources if they where processed, and the words do not add much value to the data. Stop words are words like: \"a\", \"the\", \"is\", … and so on.\nOther words can be removed based on the analysis, for example I removed \"http\" because it is part of a web address, and therefore not very useful to me. However you can filter words differently, and customize your analysis depending on it’s needs.\n\n\n\nThis is the number of characters that each Tweet contains. Tweets have a maximum of 280 characters. The dotted line in the middle of the x axis is at the 140 mark for characters, so it is just a reference point. For more details about characters in Twitter, click here to check out a character counter and more info about Twitter’s character quirks.\n\n\n\n\n\nFor each topic I collected varying amounts of data, and I did this to show how different each topic can be based on the amount of data collected, and how the word filters and sentiment values can impact the insights from this type of analysis.\n\n\n\nWhen it came to Tweets about Rocket League, the sentiment varied, but overall the average sentiment was positive. There was a lot of data collected, and as the character count increased the Tweets trended to be more positive.\n\n\n\n\n\nTweets about Pokémon Go where fairly even as far as sentiment, with many “shorter” tweets being both positive and negative, as the Tweets became longer, the both positive and negative sentiment where distributed quite evenly, but many positive tweets actually Trended upward, with groups of Tweets becoming more positive with more characters.\nThis tells me that the recent Pokémon Go events likely where enjoyed by many, but had some critiques. Additional analysis can give us more insights into the experiences of these users.\n\n\n\n\n\nTweets about TopGolf where very positive compared to the other topics, of course this is a completely different topic as Rocket League and Pokémon Go are video games, and TopGolf is an entertainment venue. There is a number of Tweets with negative sentiment, and these can be looked into and in the event that the users Tweeted about issues they had, as a company, this data can be used to fix those issues for future customers, but also reach out to users with a bad experience and offer compensation, ask for more details, etc.\n\n\n\n\n#rstats was the one topic in this project that was a Hashtag in user’s Tweets. As I expected the sentiment is mostly positive however the is negative sentiment on Twitter. Not much data was collected, however near the maximum character count is where a large portion of the Tweets for this topic are.\n\n\n\n\nI am aware that it may be hard to see every dot, when each plot is rendered alone you can read the points much easier. However, for this project I had to shrink the images so they all could be “stitched” together using the patchwork package, and allowing the final image to fit on the webpage. I could have showed each one rendered alone, but I think it is important to see them all stitched together so I could demonstrate the importance of the data collection and cleaning stages for this analysis.\n\n\n\n\n\n\n\nThis project is not meant to be used to draw an opinion of any mentioned brand, product, community, etc. It is not meant to be used to make assumptions or say if something is “good” or not. This project is meant to show this specific type of analysis. The data used in this project was obtained in compliance with Twitter Developer policies.\nI picked these topics because I enjoy playing both Rocket League and Pokémon Go. I enjoy going to play at TopGolf, and I find the technology there interesting. Lastly because of my data background the #rstats hashtag is relevant to me."
  },
  {
    "objectID": "wordpatchwork.html",
    "href": "wordpatchwork.html",
    "title": "Twitter Analysis Project",
    "section": "",
    "text": "The word correlations are quite unique and in this case they offer a different way to evaluate Tweets about a specific topic. This is done with a pairwise correlation, which will be able to tell us what words are “linked” together, or “Tweeted” often together.\nInterpretation example:\n\nOf all the sampled Tweets mentioning Pokémon Go, over 250 of them mentioned YouTube, the terms Spoofer and Hack where both highly correlated( r > .8) with YouTube.\n\n\n\n\nBecause of the different parameters for each topic, the plots are quite different from each other. I wanted to show this variation because it can make this analysis very insightful, or not. This is because different variables such as the amount of data collected, the words filtered out, the word correlation filter and the number of Tweets filter can impact this type of analysis.\n\n\n\nThe Rocket League visual shows a great amount of data collected, but the words and connections do not tell us that much about Rocket League. To remedy this for better insights we would need to be more selective with our words we filter.\n\n\n\n\n\nThe Pokémon Go visual is fairly good, it shows a “clearer message” than the Rocket League visual but it only shows a couple different “sub-topics”, with a lower number of Tweets about Pokémon Go. This indicates that we can be a bit less selective with our words filtered and balance this with collecting more data.\n\n\n\n\n\nThe TopGolf visual is quite balanced. It was one topic that I collected less data about, and more word filtering. This visual provides a few common “themes” that Twitter users are mentioning in Tweets about TopGolf.\n\n\n\n\n\nThe #rstats visual is quite insightful. The number of Tweets and correlations are balanced for being able to pick up themes about the topic, and this can actually help me see what types of skills I may want to build in order to get more experience in this field and know what is popular for the #rstats Hashtag.\n\n\n\n\n\nI am aware that some of the text is hard to read, when each plot is rendered alone you can read the text much easier. However, for this project I had to shrink the images so they all could be “stitched” together using the patchwork package, and allowing the final image to fit on the webpage. I could have showed each one rendered alone, but I think it is important to see them all stitched together so I could demonstrate the importance of the data collection and cleaning stages for this analysis."
  }
]